Language Processing! v01
Loading libraries...
Reading Book...
Found 2718 unique words tokens.
Intented vocabulary size of 3000

 Example sentence: SENTENCE_START One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin. SENTENCE_END

 Example sentence after processing: ['SENTENCE_START', 'One', 'morning', ',', 'when', 'Gregor', 'Samsa', 'woke', 'from', 'troubled', 'dreams', ',', 'he', 'found', 'himself', 'transformed', 'in', 'his', 'bed', 'into', 'a', 'horrible', 'vermin', '.', 'SENTENCE_END']
2018-03-11 13:02:00: Loss after number of samples seen = 0, epoch = 1: 7.907617
2018-03-11 13:02:16: Loss after number of samples seen = 50, epoch = 2: 225.232014
Setting learning rate to 0.025000
2018-03-11 13:02:32: Loss after number of samples seen = 100, epoch = 3: 68.949063
2018-03-11 13:02:49: Loss after number of samples seen = 150, epoch = 4: 51.530563
2018-03-11 13:03:04: Loss after number of samples seen = 200, epoch = 5: 73.594481
Setting learning rate to 0.012500
2018-03-11 13:03:21: Loss after number of samples seen = 250, epoch = 6: 7.547481
2018-03-11 13:03:38: Loss after number of samples seen = 300, epoch = 7: 7.482700
2018-03-11 13:03:54: Loss after number of samples seen = 350, epoch = 8: 7.468002
2018-03-11 13:04:08: Loss after number of samples seen = 400, epoch = 9: 7.461006
2018-03-11 13:04:24: Loss after number of samples seen = 450, epoch = 10: 7.456490
2018-03-11 13:04:40: Loss after number of samples seen = 500, epoch = 11: 7.453136
2018-03-11 13:04:58: Loss after number of samples seen = 550, epoch = 12: 7.450489
2018-03-11 13:05:16: Loss after number of samples seen = 600, epoch = 13: 7.448348
2018-03-11 13:05:35: Loss after number of samples seen = 650, epoch = 14: 7.446604
2018-03-11 13:05:53: Loss after number of samples seen = 700, epoch = 15: 7.445178
2018-03-11 13:06:13: Loss after number of samples seen = 750, epoch = 16: 7.444011
2018-03-11 13:06:31: Loss after number of samples seen = 800, epoch = 17: 7.443050
2018-03-11 13:06:48: Loss after number of samples seen = 850, epoch = 18: 7.442241
2018-03-11 13:07:06: Loss after number of samples seen = 900, epoch = 19: 7.441512
2018-03-11 13:07:23: Loss after number of samples seen = 950, epoch = 20: 7.440697
2018-03-11 13:07:40: Loss after number of samples seen = 1000, epoch = 21: 7.442797
Setting learning rate to 0.006250
2018-03-11 13:07:57: Loss after number of samples seen = 1050, epoch = 22: 7.185116
2018-03-11 13:08:18: Loss after number of samples seen = 1100, epoch = 23: 7.172430
2018-03-11 13:08:37: Loss after number of samples seen = 1150, epoch = 24: 7.168372
2018-03-11 13:08:57: Loss after number of samples seen = 1200, epoch = 25: 7.166349
2018-03-11 13:09:13: Loss after number of samples seen = 1250, epoch = 26: 7.165030
2018-03-11 13:09:29: Loss after number of samples seen = 1300, epoch = 27: 7.164010
2018-03-11 13:09:46: Loss after number of samples seen = 1350, epoch = 28: 7.163144
2018-03-11 13:10:04: Loss after number of samples seen = 1400, epoch = 29: 7.162365
2018-03-11 13:10:20: Loss after number of samples seen = 1450, epoch = 30: 7.161643
2018-03-11 13:10:35: Loss after number of samples seen = 1500, epoch = 31: 7.160959
2018-03-11 13:10:52: Loss after number of samples seen = 1550, epoch = 32: 7.160303
2018-03-11 13:11:08: Loss after number of samples seen = 1600, epoch = 33: 7.159668
2018-03-11 13:11:23: Loss after number of samples seen = 1650, epoch = 34: 7.159052
2018-03-11 13:11:39: Loss after number of samples seen = 1700, epoch = 35: 7.158450
2018-03-11 13:11:56: Loss after number of samples seen = 1750, epoch = 36: 7.157861
2018-03-11 13:12:13: Loss after number of samples seen = 1800, epoch = 37: 7.157284
2018-03-11 13:12:29: Loss after number of samples seen = 1850, epoch = 38: 7.156718
2018-03-11 13:12:45: Loss after number of samples seen = 1900, epoch = 39: 7.156162
2018-03-11 13:13:00: Loss after number of samples seen = 1950, epoch = 40: 7.155616
2018-03-11 13:13:15: Loss after number of samples seen = 2000, epoch = 41: 7.155078
2018-03-11 13:13:32: Loss after number of samples seen = 2050, epoch = 42: 7.154549
2018-03-11 13:13:46: Loss after number of samples seen = 2100, epoch = 43: 7.154027
2018-03-11 13:14:01: Loss after number of samples seen = 2150, epoch = 44: 7.153514
2018-03-11 13:14:15: Loss after number of samples seen = 2200, epoch = 45: 7.153008
2018-03-11 13:14:29: Loss after number of samples seen = 2250, epoch = 46: 7.152509
2018-03-11 13:14:43: Loss after number of samples seen = 2300, epoch = 47: 7.152017
2018-03-11 13:14:59: Loss after number of samples seen = 2350, epoch = 48: 7.151533
2018-03-11 13:15:13: Loss after number of samples seen = 2400, epoch = 49: 7.151055
2018-03-11 13:15:27: Loss after number of samples seen = 2450, epoch = 50: 7.150583
His previous resolved noticing o'clock upwards subordinates convinced occupational kitchen towards draught instrument reported 's desk , seen lungs minutes picked On agreed so their of shoulder be unhappy accept peering to me brother strong also out ; for against endless like packed roll object Gregor joined spare he directions with other tone shoulders tightly body itch expectations diligently alert nearby seen mingle especially try The noticed anything noise disturbed ever but overcome noticeable cash sending mother carefully voice side
